{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MVP: Drug-Disease Adverse Outcome Prediction\n",
        "\n",
        "**Scope**: 1-2 disease areas, 10-20 drugs with known adverse outcomes, binary outcome prediction\n",
        "\n",
        "**Approach**:\n",
        "- **GDi**: Disease → Associated Genes (PrimeKG) → Pathways (PrimeKG)\n",
        "- **GDr**: Drugs → Target Genes (PrimeKG) → Pathways (PrimeKG)\n",
        "- **Features**: Shared genes, shared pathways, pathway overlap, graph distance\n",
        "- **Baseline**: Simple PrimeKG embeddings\n",
        "- **Models**: Logistic Regression & Random Forest (no GNNs yet)\n",
        "\n",
        "**Reference**: See `explore_primekg.ipynb` for PrimeKG dataset details\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install pandas numpy networkx scikit-learn matplotlib seaborn tqdm requests node2vec -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from collections import defaultdict, Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "print(\"Dependencies loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download PrimeKG\n",
        "\n",
        "PrimeKG is available from Harvard Dataverse. Reference: `explore_primekg.ipynb` for details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# PrimeKG download URL from Harvard Dataverse\n",
        "PRIMEKG_URL = \"https://dataverse.harvard.edu/api/access/datafile/6180620\"\n",
        "DATA_PATH = \"kg.csv\"\n",
        "\n",
        "def download_primekg(url, filepath, chunk_size=8192):\n",
        "    \"\"\"Download PrimeKG dataset with progress bar.\"\"\"\n",
        "    if os.path.exists(filepath):\n",
        "        print(f\"Dataset already exists at {filepath}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"Downloading PrimeKG from {url}...\")\n",
        "    print(\"Note: This is ~1GB and may take several minutes.\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    total_size = int(response.headers.get('content-length', 0))\n",
        "    \n",
        "    with open(filepath, 'wb') as f:\n",
        "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Downloading\") as pbar:\n",
        "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "    \n",
        "    print(f\"Download complete! Saved to {filepath}\")\n",
        "\n",
        "# Download the dataset\n",
        "download_primekg(PRIMEKG_URL, DATA_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load PrimeKG Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "print(\"Loading PrimeKG dataset...\")\n",
        "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
        "print(f\"Dataset loaded: {df.shape[0]:,} edges, {df.shape[1]} columns\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Select Disease Areas & Drugs with Adverse Outcomes\n",
        "\n",
        "We'll focus on diseases with contraindications (known adverse drug outcomes).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract drug-disease relationships\n",
        "drug_disease_mask = (\n",
        "    ((df['x_type'] == 'drug') & (df['y_type'] == 'disease')) |\n",
        "    ((df['x_type'] == 'disease') & (df['y_type'] == 'drug'))\n",
        ")\n",
        "drug_disease_df = df[drug_disease_mask].copy()\n",
        "\n",
        "# Normalize direction: always drug -> disease\n",
        "def normalize_drug_disease(row):\n",
        "    if row['x_type'] == 'drug':\n",
        "        return pd.Series({\n",
        "            'drug_id': row['x_id'],\n",
        "            'drug_name': row['x_name'],\n",
        "            'disease_id': row['y_id'],\n",
        "            'disease_name': row['y_name'],\n",
        "            'relation': row['relation']\n",
        "        })\n",
        "    else:\n",
        "        return pd.Series({\n",
        "            'drug_id': row['y_id'],\n",
        "            'drug_name': row['y_name'],\n",
        "            'disease_id': row['x_id'],\n",
        "            'disease_name': row['x_name'],\n",
        "            'relation': row['relation']\n",
        "        })\n",
        "\n",
        "drug_disease_normalized = drug_disease_df.apply(normalize_drug_disease, axis=1)\n",
        "\n",
        "print(f\"Total drug-disease edges: {len(drug_disease_normalized):,}\")\n",
        "print(f\"\\nRelationship types:\")\n",
        "print(drug_disease_normalized['relation'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select 1-2 disease areas with many contraindications (adverse outcomes)\n",
        "contraindications = drug_disease_normalized[drug_disease_normalized['relation'] == 'contraindication']\n",
        "\n",
        "# Find diseases with most contraindications\n",
        "disease_contra_counts = contraindications.groupby(['disease_id', 'disease_name']).size().reset_index(name='contra_count')\n",
        "disease_contra_counts = disease_contra_counts.sort_values('contra_count', ascending=False)\n",
        "\n",
        "print(\"Top diseases with contraindications (adverse outcomes):\")\n",
        "print(disease_contra_counts.head(10))\n",
        "\n",
        "# Select top 1-2 disease areas\n",
        "selected_diseases = disease_contra_counts.head(2)\n",
        "selected_disease_ids = selected_diseases['disease_id'].tolist()\n",
        "selected_disease_names = selected_diseases['disease_name'].tolist()\n",
        "\n",
        "print(f\"\\nSelected disease areas:\")\n",
        "for did, dname in zip(selected_disease_ids, selected_disease_names):\n",
        "    print(f\"  - {dname} (ID: {did})\")\n",
        "\n",
        "# Get drugs with contraindications for selected diseases\n",
        "selected_contraindications = contraindications[contraindications['disease_id'].isin(selected_disease_ids)]\n",
        "drug_contra_counts = selected_contraindications.groupby(['drug_id', 'drug_name']).size().reset_index(name='contra_count')\n",
        "drug_contra_counts = drug_contra_counts.sort_values('contra_count', ascending=False)\n",
        "\n",
        "print(f\"\\nDrugs with contraindications for selected diseases: {len(drug_contra_counts)}\")\n",
        "\n",
        "# Select 10-20 drugs\n",
        "n_drugs = min(20, len(drug_contra_counts))\n",
        "selected_drugs = drug_contra_counts.head(n_drugs)\n",
        "selected_drug_ids = selected_drugs['drug_id'].tolist()\n",
        "selected_drug_names = selected_drugs['drug_name'].tolist()\n",
        "\n",
        "print(f\"\\nSelected {len(selected_drug_ids)} drugs:\")\n",
        "for did, dname in zip(selected_drug_ids[:10], selected_drug_names[:10]):\n",
        "    print(f\"  - {dname} (ID: {did})\")\n",
        "if len(selected_drug_ids) > 10:\n",
        "    print(f\"  ... and {len(selected_drug_ids) - 10} more\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Build GDi and GDr Mappings\n",
        "\n",
        "**GDi**: Disease → Genes → Pathways  \n",
        "**GDr**: Drug → Target Genes → Pathways\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build GDi: Disease → Genes → Pathways\n",
        "print(\"Building GDi: Disease → Genes → Pathways\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Step 1: Disease → Genes (disease_protein relation)\n",
        "disease_gene_edges = df[\n",
        "    ((df['x_type'] == 'disease') & (df['y_type'] == 'gene/protein') & (df['relation'] == 'disease_protein')) |\n",
        "    ((df['x_type'] == 'gene/protein') & (df['y_type'] == 'disease') & (df['relation'] == 'disease_protein'))\n",
        "].copy()\n",
        "\n",
        "# Normalize to disease -> gene\n",
        "def normalize_disease_gene(row):\n",
        "    if row['x_type'] == 'disease':\n",
        "        return pd.Series({\n",
        "            'disease_id': row['x_id'],\n",
        "            'disease_name': row['x_name'],\n",
        "            'gene_id': row['y_id'],\n",
        "            'gene_name': row['y_name']\n",
        "        })\n",
        "    else:\n",
        "        return pd.Series({\n",
        "            'disease_id': row['y_id'],\n",
        "            'disease_name': row['y_name'],\n",
        "            'gene_id': row['x_id'],\n",
        "            'gene_name': row['x_name']\n",
        "        })\n",
        "\n",
        "disease_gene_df = disease_gene_edges.apply(normalize_disease_gene, axis=1)\n",
        "\n",
        "# Step 2: Genes → Pathways (pathway_protein relation)\n",
        "gene_pathway_edges = df[\n",
        "    ((df['x_type'] == 'gene/protein') & (df['y_type'] == 'pathway') & (df['relation'] == 'pathway_protein')) |\n",
        "    ((df['x_type'] == 'pathway') & (df['y_type'] == 'gene/protein') & (df['relation'] == 'pathway_protein'))\n",
        "].copy()\n",
        "\n",
        "def normalize_gene_pathway(row):\n",
        "    if row['x_type'] == 'gene/protein':\n",
        "        return pd.Series({\n",
        "            'gene_id': row['x_id'],\n",
        "            'gene_name': row['x_name'],\n",
        "            'pathway_id': row['y_id'],\n",
        "            'pathway_name': row['y_name']\n",
        "        })\n",
        "    else:\n",
        "        return pd.Series({\n",
        "            'gene_id': row['y_id'],\n",
        "            'gene_name': row['y_name'],\n",
        "            'pathway_id': row['x_id'],\n",
        "            'pathway_name': row['x_name']\n",
        "        })\n",
        "\n",
        "gene_pathway_df = gene_pathway_edges.apply(normalize_gene_pathway, axis=1)\n",
        "\n",
        "# Build GDi mapping: disease_id -> {gene_ids} -> {pathway_ids}\n",
        "gdi_disease_genes = defaultdict(set)\n",
        "gdi_gene_pathways = defaultdict(set)\n",
        "gdi_disease_pathways = defaultdict(set)\n",
        "\n",
        "# Disease -> Genes\n",
        "for _, row in disease_gene_df.iterrows():\n",
        "    gdi_disease_genes[row['disease_id']].add(row['gene_id'])\n",
        "\n",
        "# Gene -> Pathways\n",
        "for _, row in gene_pathway_df.iterrows():\n",
        "    gdi_gene_pathways[row['gene_id']].add(row['pathway_id'])\n",
        "\n",
        "# Disease -> Pathways (via genes)\n",
        "for disease_id, gene_ids in gdi_disease_genes.items():\n",
        "    for gene_id in gene_ids:\n",
        "        if gene_id in gdi_gene_pathways:\n",
        "            gdi_disease_pathways[disease_id].update(gdi_gene_pathways[gene_id])\n",
        "\n",
        "print(f\"Diseases with gene associations: {len(gdi_disease_genes)}\")\n",
        "print(f\"Genes with pathway associations: {len(gdi_gene_pathways)}\")\n",
        "print(f\"Diseases with pathway associations: {len(gdi_disease_pathways)}\")\n",
        "\n",
        "# Check selected diseases\n",
        "for disease_id in selected_disease_ids:\n",
        "    n_genes = len(gdi_disease_genes.get(disease_id, set()))\n",
        "    n_pathways = len(gdi_disease_pathways.get(disease_id, set()))\n",
        "    disease_name = selected_diseases[selected_diseases['disease_id'] == disease_id]['disease_name'].values[0]\n",
        "    print(f\"\\n{disease_name}:\")\n",
        "    print(f\"  Genes: {n_genes}, Pathways: {n_pathways}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build GDr: Drug → Target Genes → Pathways\n",
        "print(\"Building GDr: Drug → Target Genes → Pathways\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Step 1: Drug → Target Genes (drug_protein relation)\n",
        "drug_gene_edges = df[\n",
        "    ((df['x_type'] == 'drug') & (df['y_type'] == 'gene/protein') & (df['relation'] == 'drug_protein')) |\n",
        "    ((df['x_type'] == 'gene/protein') & (df['y_type'] == 'drug') & (df['relation'] == 'drug_protein'))\n",
        "].copy()\n",
        "\n",
        "def normalize_drug_gene(row):\n",
        "    if row['x_type'] == 'drug':\n",
        "        return pd.Series({\n",
        "            'drug_id': row['x_id'],\n",
        "            'drug_name': row['x_name'],\n",
        "            'gene_id': row['y_id'],\n",
        "            'gene_name': row['y_name']\n",
        "        })\n",
        "    else:\n",
        "        return pd.Series({\n",
        "            'drug_id': row['y_id'],\n",
        "            'drug_name': row['y_name'],\n",
        "            'gene_id': row['x_id'],\n",
        "            'gene_name': row['x_name']\n",
        "        })\n",
        "\n",
        "drug_gene_df = drug_gene_edges.apply(normalize_drug_gene, axis=1)\n",
        "\n",
        "# Build GDr mapping: drug_id -> {gene_ids} -> {pathway_ids}\n",
        "gdr_drug_genes = defaultdict(set)\n",
        "gdr_drug_pathways = defaultdict(set)\n",
        "\n",
        "# Drug -> Genes\n",
        "for _, row in drug_gene_df.iterrows():\n",
        "    gdr_drug_genes[row['drug_id']].add(row['gene_id'])\n",
        "\n",
        "# Drug -> Pathways (via genes, reuse gene_pathway mapping)\n",
        "for drug_id, gene_ids in gdr_drug_genes.items():\n",
        "    for gene_id in gene_ids:\n",
        "        if gene_id in gdi_gene_pathways:\n",
        "            gdr_drug_pathways[drug_id].update(gdi_gene_pathways[gene_id])\n",
        "\n",
        "print(f\"Drugs with gene targets: {len(gdr_drug_genes)}\")\n",
        "print(f\"Drugs with pathway associations: {len(gdr_drug_pathways)}\")\n",
        "\n",
        "# Check selected drugs\n",
        "for drug_id in selected_drug_ids[:5]:\n",
        "    n_genes = len(gdr_drug_genes.get(drug_id, set()))\n",
        "    n_pathways = len(gdr_drug_pathways.get(drug_id, set()))\n",
        "    drug_name = selected_drugs[selected_drugs['drug_id'] == drug_id]['drug_name'].values[0]\n",
        "    print(f\"\\n{drug_name}:\")\n",
        "    print(f\"  Target Genes: {n_genes}, Pathways: {n_pathways}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Build NetworkX Graph for Distance Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build a simplified NetworkX graph for computing distances\n",
        "# We'll include: drugs, diseases, genes, pathways\n",
        "print(\"Building NetworkX graph for distance computation...\")\n",
        "\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes with types\n",
        "node_info = {}\n",
        "\n",
        "# Add disease nodes\n",
        "for disease_id in selected_disease_ids:\n",
        "    G.add_node(disease_id, node_type='disease')\n",
        "    disease_name = selected_diseases[selected_diseases['disease_id'] == disease_id]['disease_name'].values[0]\n",
        "    node_info[disease_id] = {'name': disease_name, 'type': 'disease'}\n",
        "\n",
        "# Add drug nodes\n",
        "for drug_id in selected_drug_ids:\n",
        "    G.add_node(drug_id, node_type='drug')\n",
        "    drug_name = selected_drugs[selected_drugs['drug_id'] == drug_id]['drug_name'].values[0]\n",
        "    node_info[drug_id] = {'name': drug_name, 'type': 'drug'}\n",
        "\n",
        "# Add gene nodes and edges\n",
        "all_genes = set()\n",
        "for disease_id in selected_disease_ids:\n",
        "    all_genes.update(gdi_disease_genes.get(disease_id, set()))\n",
        "for drug_id in selected_drug_ids:\n",
        "    all_genes.update(gdr_drug_genes.get(drug_id, set()))\n",
        "\n",
        "for gene_id in all_genes:\n",
        "    G.add_node(gene_id, node_type='gene')\n",
        "    node_info[gene_id] = {'name': f'Gene_{gene_id}', 'type': 'gene'}\n",
        "\n",
        "# Add pathway nodes\n",
        "all_pathways = set()\n",
        "for disease_id in selected_disease_ids:\n",
        "    all_pathways.update(gdi_disease_pathways.get(disease_id, set()))\n",
        "for drug_id in selected_drug_ids:\n",
        "    all_pathways.update(gdr_drug_pathways.get(drug_id, set()))\n",
        "\n",
        "for pathway_id in all_pathways:\n",
        "    G.add_node(pathway_id, node_type='pathway')\n",
        "    node_info[pathway_id] = {'name': f'Pathway_{pathway_id}', 'type': 'pathway'}\n",
        "\n",
        "# Add edges: disease-gene, drug-gene, gene-pathway\n",
        "for disease_id in selected_disease_ids:\n",
        "    for gene_id in gdi_disease_genes.get(disease_id, set()):\n",
        "        G.add_edge(disease_id, gene_id, relation='disease_gene')\n",
        "\n",
        "for drug_id in selected_drug_ids:\n",
        "    for gene_id in gdr_drug_genes.get(drug_id, set()):\n",
        "        G.add_edge(drug_id, gene_id, relation='drug_gene')\n",
        "\n",
        "for gene_id in all_genes:\n",
        "    for pathway_id in gdi_gene_pathways.get(gene_id, set()):\n",
        "        if pathway_id in all_pathways:\n",
        "            G.add_edge(gene_id, pathway_id, relation='gene_pathway')\n",
        "\n",
        "print(f\"Graph built: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "print(f\"  Diseases: {len(selected_disease_ids)}\")\n",
        "print(f\"  Drugs: {len(selected_drug_ids)}\")\n",
        "print(f\"  Genes: {len(all_genes)}\")\n",
        "print(f\"  Pathways: {len(all_pathways)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Extract Interaction Features\n",
        "\n",
        "For each drug-disease pair, extract:\n",
        "1. Shared genes count\n",
        "2. Shared pathways count\n",
        "3. Pathway coverage overlap (Jaccard similarity)\n",
        "4. Graph distance between drug and disease nodes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_pathway_overlap(disease_pathways, drug_pathways):\n",
        "    \"\"\"Compute Jaccard similarity of pathway sets.\"\"\"\n",
        "    if len(disease_pathways) == 0 and len(drug_pathways) == 0:\n",
        "        return 0.0\n",
        "    intersection = len(disease_pathways & drug_pathways)\n",
        "    union = len(disease_pathways | drug_pathways)\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "def compute_graph_distance(G, drug_id, disease_id):\n",
        "    \"\"\"Compute shortest path distance between drug and disease.\"\"\"\n",
        "    try:\n",
        "        if drug_id not in G or disease_id not in G:\n",
        "            return -1  # Not in graph\n",
        "        distance = nx.shortest_path_length(G, drug_id, disease_id)\n",
        "        return distance\n",
        "    except nx.NetworkXNoPath:\n",
        "        return -1  # No path exists\n",
        "\n",
        "def extract_features(drug_id, disease_id, gdi_disease_genes, gdi_disease_pathways,\n",
        "                     gdr_drug_genes, gdr_drug_pathways, G):\n",
        "    \"\"\"Extract all interaction features for a drug-disease pair.\"\"\"\n",
        "    # Get gene and pathway sets\n",
        "    disease_genes = gdi_disease_genes.get(disease_id, set())\n",
        "    disease_pathways = gdi_disease_pathways.get(disease_id, set())\n",
        "    drug_genes = gdr_drug_genes.get(drug_id, set())\n",
        "    drug_pathways = gdr_drug_pathways.get(drug_id, set())\n",
        "    \n",
        "    # Feature 1: Shared genes count\n",
        "    shared_genes = disease_genes & drug_genes\n",
        "    n_shared_genes = len(shared_genes)\n",
        "    \n",
        "    # Feature 2: Shared pathways count\n",
        "    shared_pathways = disease_pathways & drug_pathways\n",
        "    n_shared_pathways = len(shared_pathways)\n",
        "    \n",
        "    # Feature 3: Pathway overlap (Jaccard similarity)\n",
        "    pathway_overlap = compute_pathway_overlap(disease_pathways, drug_pathways)\n",
        "    \n",
        "    # Feature 4: Graph distance\n",
        "    graph_distance = compute_graph_distance(G, drug_id, disease_id)\n",
        "    \n",
        "    # Additional features\n",
        "    n_disease_genes = len(disease_genes)\n",
        "    n_disease_pathways = len(disease_pathways)\n",
        "    n_drug_genes = len(drug_genes)\n",
        "    n_drug_pathways = len(drug_pathways)\n",
        "    \n",
        "    return {\n",
        "        'n_shared_genes': n_shared_genes,\n",
        "        'n_shared_pathways': n_shared_pathways,\n",
        "        'pathway_overlap': pathway_overlap,\n",
        "        'graph_distance': graph_distance,\n",
        "        'n_disease_genes': n_disease_genes,\n",
        "        'n_disease_pathways': n_disease_pathways,\n",
        "        'n_drug_genes': n_drug_genes,\n",
        "        'n_drug_pathways': n_drug_pathways,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataset: all drug-disease pairs with labels and features\n",
        "print(\"Creating dataset with features...\")\n",
        "\n",
        "dataset = []\n",
        "\n",
        "# Positive examples: contraindications (adverse outcomes)\n",
        "positive_pairs = contraindications[\n",
        "    (contraindications['disease_id'].isin(selected_disease_ids)) &\n",
        "    (contraindications['drug_id'].isin(selected_drug_ids))\n",
        "]\n",
        "\n",
        "print(f\"Positive examples (contraindications): {len(positive_pairs)}\")\n",
        "\n",
        "# Negative examples: indications (therapeutic uses) or random pairs\n",
        "indications = drug_disease_normalized[drug_disease_normalized['relation'] == 'indication']\n",
        "negative_pairs = indications[\n",
        "    (indications['disease_id'].isin(selected_disease_ids)) &\n",
        "    (indications['drug_id'].isin(selected_drug_ids))\n",
        "]\n",
        "\n",
        "# If not enough negative examples, add random pairs\n",
        "if len(negative_pairs) < len(positive_pairs):\n",
        "    # Generate random drug-disease pairs\n",
        "    all_pairs = set(zip(positive_pairs['drug_id'], positive_pairs['disease_id']))\n",
        "    all_pairs.update(zip(negative_pairs['drug_id'], negative_pairs['disease_id']))\n",
        "    \n",
        "    needed = len(positive_pairs) - len(negative_pairs)\n",
        "    random_pairs = []\n",
        "    attempts = 0\n",
        "    while len(random_pairs) < needed and attempts < 10000:\n",
        "        drug_id = np.random.choice(selected_drug_ids)\n",
        "        disease_id = np.random.choice(selected_disease_ids)\n",
        "        if (drug_id, disease_id) not in all_pairs:\n",
        "            random_pairs.append((drug_id, disease_id))\n",
        "            all_pairs.add((drug_id, disease_id))\n",
        "        attempts += 1\n",
        "    \n",
        "    if random_pairs:\n",
        "        random_df = pd.DataFrame(random_pairs, columns=['drug_id', 'disease_id'])\n",
        "        random_df['drug_name'] = random_df['drug_id'].map(dict(zip(selected_drugs['drug_id'], selected_drugs['drug_name'])))\n",
        "        random_df['disease_name'] = random_df['disease_id'].map(dict(zip(selected_diseases['disease_id'], selected_diseases['disease_name'])))\n",
        "        random_df['relation'] = 'none'\n",
        "        negative_pairs = pd.concat([negative_pairs, random_df], ignore_index=True)\n",
        "\n",
        "print(f\"Negative examples: {len(negative_pairs)}\")\n",
        "\n",
        "# Extract features for positive pairs\n",
        "for _, row in tqdm(positive_pairs.iterrows(), total=len(positive_pairs), desc=\"Positive pairs\"):\n",
        "    features = extract_features(\n",
        "        row['drug_id'], row['disease_id'],\n",
        "        gdi_disease_genes, gdi_disease_pathways,\n",
        "        gdr_drug_genes, gdr_drug_pathways, G\n",
        "    )\n",
        "    features['drug_id'] = row['drug_id']\n",
        "    features['drug_name'] = row['drug_name']\n",
        "    features['disease_id'] = row['disease_id']\n",
        "    features['disease_name'] = row['disease_name']\n",
        "    features['label'] = 1  # Adverse outcome\n",
        "    dataset.append(features)\n",
        "\n",
        "# Extract features for negative pairs\n",
        "for _, row in tqdm(negative_pairs.iterrows(), total=len(negative_pairs), desc=\"Negative pairs\"):\n",
        "    features = extract_features(\n",
        "        row['drug_id'], row['disease_id'],\n",
        "        gdi_disease_genes, gdi_disease_pathways,\n",
        "        gdr_drug_genes, gdr_drug_pathways, G\n",
        "    )\n",
        "    features['drug_id'] = row['drug_id']\n",
        "    features['drug_name'] = row['drug_name']\n",
        "    features['disease_id'] = row['disease_id']\n",
        "    features['disease_name'] = row['disease_name']\n",
        "    features['label'] = 0  # No adverse outcome\n",
        "    dataset.append(features)\n",
        "\n",
        "df_dataset = pd.DataFrame(dataset)\n",
        "\n",
        "print(f\"\\nDataset created: {len(df_dataset)} examples\")\n",
        "print(f\"  Positive (adverse): {df_dataset['label'].sum()}\")\n",
        "print(f\"  Negative (safe): {len(df_dataset) - df_dataset['label'].sum()}\")\n",
        "print(f\"\\nFeature statistics:\")\n",
        "print(df_dataset.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Baseline: Simple PrimeKG Embeddings\n",
        "\n",
        "Create simple node embeddings using graph structure (e.g., node2vec or degree-based features).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple baseline: Use node degrees and centrality measures as embeddings\n",
        "print(\"Creating baseline embeddings...\")\n",
        "\n",
        "# Compute node degrees\n",
        "degrees = dict(G.degree())\n",
        "\n",
        "# Compute centrality measures (for a subset if graph is large)\n",
        "if G.number_of_nodes() < 10000:\n",
        "    print(\"Computing centrality measures...\")\n",
        "    betweenness = nx.betweenness_centrality(G)\n",
        "    closeness = nx.closeness_centrality(G)\n",
        "else:\n",
        "    print(\"Graph too large, using degree only...\")\n",
        "    betweenness = {n: 0.0 for n in G.nodes()}\n",
        "    closeness = {n: 0.0 for n in G.nodes()}\n",
        "\n",
        "# Create embedding features for each drug-disease pair\n",
        "baseline_features = []\n",
        "for _, row in df_dataset.iterrows():\n",
        "    drug_id = row['drug_id']\n",
        "    disease_id = row['disease_id']\n",
        "    \n",
        "    drug_degree = degrees.get(drug_id, 0)\n",
        "    disease_degree = degrees.get(disease_id, 0)\n",
        "    drug_betweenness = betweenness.get(drug_id, 0.0)\n",
        "    disease_betweenness = betweenness.get(disease_id, 0.0)\n",
        "    drug_closeness = closeness.get(drug_id, 0.0)\n",
        "    disease_closeness = closeness.get(disease_id, 0.0)\n",
        "    \n",
        "    baseline_features.append({\n",
        "        'drug_degree': drug_degree,\n",
        "        'disease_degree': disease_degree,\n",
        "        'drug_betweenness': drug_betweenness,\n",
        "        'disease_betweenness': disease_betweenness,\n",
        "        'drug_closeness': drug_closeness,\n",
        "        'disease_closeness': disease_closeness,\n",
        "        'degree_sum': drug_degree + disease_degree,\n",
        "        'degree_diff': abs(drug_degree - disease_degree),\n",
        "    })\n",
        "\n",
        "df_baseline = pd.DataFrame(baseline_features)\n",
        "print(f\"Baseline features created: {df_baseline.shape[1]} features\")\n",
        "print(df_baseline.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Train Models\n",
        "\n",
        "Train Logistic Regression and Random Forest models on:\n",
        "1. Interaction features only\n",
        "2. Baseline embeddings only\n",
        "3. Combined features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare feature sets\n",
        "feature_cols = [\n",
        "    'n_shared_genes', 'n_shared_pathways', 'pathway_overlap', 'graph_distance',\n",
        "    'n_disease_genes', 'n_disease_pathways', 'n_drug_genes', 'n_drug_pathways'\n",
        "]\n",
        "\n",
        "baseline_cols = list(df_baseline.columns)\n",
        "\n",
        "# Handle missing values (graph_distance = -1 means no path)\n",
        "df_dataset['graph_distance'] = df_dataset['graph_distance'].replace(-1, df_dataset['graph_distance'].max() + 1)\n",
        "\n",
        "X_interaction = df_dataset[feature_cols].values\n",
        "X_baseline = df_baseline.values\n",
        "X_combined = np.hstack([X_interaction, X_baseline])\n",
        "\n",
        "y = df_dataset['label'].values\n",
        "\n",
        "# Train-test split\n",
        "X_interaction_train, X_interaction_test, y_train, y_test = train_test_split(\n",
        "    X_interaction, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_baseline_train, X_baseline_test, _, _ = train_test_split(\n",
        "    X_baseline, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_combined_train, X_combined_test, _, _ = train_test_split(\n",
        "    X_combined, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set: {len(y_train)} examples\")\n",
        "print(f\"Test set: {len(y_test)} examples\")\n",
        "print(f\"  Positive in train: {y_train.sum()}, test: {y_test.sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Logistic Regression models\n",
        "print(\"Training Logistic Regression models...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "models = {}\n",
        "results = {}\n",
        "\n",
        "# 1. Interaction features only\n",
        "lr_interaction = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_interaction.fit(X_interaction_train, y_train)\n",
        "y_pred_interaction = lr_interaction.predict(X_interaction_test)\n",
        "y_proba_interaction = lr_interaction.predict_proba(X_interaction_test)[:, 1]\n",
        "\n",
        "models['LR_Interaction'] = lr_interaction\n",
        "results['LR_Interaction'] = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_interaction),\n",
        "    'precision': precision_score(y_test, y_pred_interaction),\n",
        "    'recall': recall_score(y_test, y_pred_interaction),\n",
        "    'f1': f1_score(y_test, y_pred_interaction),\n",
        "    'roc_auc': roc_auc_score(y_test, y_proba_interaction)\n",
        "}\n",
        "\n",
        "# 2. Baseline embeddings only\n",
        "lr_baseline = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_baseline.fit(X_baseline_train, y_train)\n",
        "y_pred_baseline = lr_baseline.predict(X_baseline_test)\n",
        "y_proba_baseline = lr_baseline.predict_proba(X_baseline_test)[:, 1]\n",
        "\n",
        "models['LR_Baseline'] = lr_baseline\n",
        "results['LR_Baseline'] = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_baseline),\n",
        "    'precision': precision_score(y_test, y_pred_baseline),\n",
        "    'recall': recall_score(y_test, y_pred_baseline),\n",
        "    'f1': f1_score(y_test, y_pred_baseline),\n",
        "    'roc_auc': roc_auc_score(y_test, y_proba_baseline)\n",
        "}\n",
        "\n",
        "# 3. Combined features\n",
        "lr_combined = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_combined.fit(X_combined_train, y_train)\n",
        "y_pred_combined = lr_combined.predict(X_combined_test)\n",
        "y_proba_combined = lr_combined.predict_proba(X_combined_test)[:, 1]\n",
        "\n",
        "models['LR_Combined'] = lr_combined\n",
        "results['LR_Combined'] = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_combined),\n",
        "    'precision': precision_score(y_test, y_pred_combined),\n",
        "    'recall': recall_score(y_test, y_pred_combined),\n",
        "    'f1': f1_score(y_test, y_pred_combined),\n",
        "    'roc_auc': roc_auc_score(y_test, y_proba_combined)\n",
        "}\n",
        "\n",
        "# Print results\n",
        "print(\"\\nLogistic Regression Results:\")\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest models\n",
        "print(\"\\nTraining Random Forest models...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Interaction features only\n",
        "rf_interaction = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_interaction.fit(X_interaction_train, y_train)\n",
        "y_pred_interaction = rf_interaction.predict(X_interaction_test)\n",
        "y_proba_interaction = rf_interaction.predict_proba(X_interaction_test)[:, 1]\n",
        "\n",
        "models['RF_Interaction'] = rf_interaction\n",
        "results['RF_Interaction'] = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_interaction),\n",
        "    'precision': precision_score(y_test, y_pred_interaction),\n",
        "    'recall': recall_score(y_test, y_pred_interaction),\n",
        "    'f1': f1_score(y_test, y_pred_interaction),\n",
        "    'roc_auc': roc_auc_score(y_test, y_proba_interaction)\n",
        "}\n",
        "\n",
        "# 2. Baseline embeddings only\n",
        "rf_baseline = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_baseline.fit(X_baseline_train, y_train)\n",
        "y_pred_baseline = rf_baseline.predict(X_baseline_test)\n",
        "y_proba_baseline = rf_baseline.predict_proba(X_baseline_test)[:, 1]\n",
        "\n",
        "models['RF_Baseline'] = rf_baseline\n",
        "results['RF_Baseline'] = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_baseline),\n",
        "    'precision': precision_score(y_test, y_pred_baseline),\n",
        "    'recall': recall_score(y_test, y_pred_baseline),\n",
        "    'f1': f1_score(y_test, y_pred_baseline),\n",
        "    'roc_auc': roc_auc_score(y_test, y_proba_baseline)\n",
        "}\n",
        "\n",
        "# 3. Combined features\n",
        "rf_combined = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_combined.fit(X_combined_train, y_train)\n",
        "y_pred_combined = rf_combined.predict(X_combined_test)\n",
        "y_proba_combined = rf_combined.predict_proba(X_combined_test)[:, 1]\n",
        "\n",
        "models['RF_Combined'] = rf_combined\n",
        "results['RF_Combined'] = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_combined),\n",
        "    'precision': precision_score(y_test, y_pred_combined),\n",
        "    'recall': recall_score(y_test, y_pred_combined),\n",
        "    'f1': f1_score(y_test, y_pred_combined),\n",
        "    'roc_auc': roc_auc_score(y_test, y_proba_combined)\n",
        "}\n",
        "\n",
        "# Print results\n",
        "print(\"\\nRandom Forest Results:\")\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df.round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Model Evaluation & Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. Accuracy comparison\n",
        "ax = axes[0, 0]\n",
        "results_df['accuracy'].plot(kind='bar', ax=ax, color='steelblue')\n",
        "ax.set_title('Model Accuracy Comparison', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_ylim([0, 1])\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 2. ROC-AUC comparison\n",
        "ax = axes[0, 1]\n",
        "results_df['roc_auc'].plot(kind='bar', ax=ax, color='coral')\n",
        "ax.set_title('ROC-AUC Comparison', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('ROC-AUC')\n",
        "ax.set_ylim([0, 1])\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 3. F1 Score comparison\n",
        "ax = axes[1, 0]\n",
        "results_df['f1'].plot(kind='bar', ax=ax, color='mediumseagreen')\n",
        "ax.set_title('F1 Score Comparison', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('F1 Score')\n",
        "ax.set_ylim([0, 1])\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 4. Feature importance (best RF model)\n",
        "ax = axes[1, 1]\n",
        "best_model_name = results_df['roc_auc'].idxmax()\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "if 'RF' in best_model_name:\n",
        "    if 'Combined' in best_model_name:\n",
        "        all_feature_names = feature_cols + baseline_cols\n",
        "        importances = best_model.feature_importances_\n",
        "    elif 'Interaction' in best_model_name:\n",
        "        all_feature_names = feature_cols\n",
        "        importances = best_model.feature_importances_\n",
        "    else:\n",
        "        all_feature_names = baseline_cols\n",
        "        importances = best_model.feature_importances_\n",
        "    \n",
        "    # Get top 10 features\n",
        "    top_indices = np.argsort(importances)[-10:][::-1]\n",
        "    top_features = [all_feature_names[i] for i in top_indices]\n",
        "    top_importances = importances[top_indices]\n",
        "    \n",
        "    ax.barh(range(len(top_features)), top_importances, color='gold')\n",
        "    ax.set_yticks(range(len(top_features)))\n",
        "    ax.set_yticklabels(top_features)\n",
        "    ax.set_xlabel('Importance')\n",
        "    ax.set_title(f'Top 10 Features: {best_model_name}', fontsize=12, fontweight='bold')\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "else:\n",
        "    ax.text(0.5, 0.5, 'Feature importance\\navailable for\\nRandom Forest only',\n",
        "            ha='center', va='center', fontsize=12, transform=ax.transAxes)\n",
        "    ax.set_title(f'Best Model: {best_model_name}', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"  ROC-AUC: {results_df.loc[best_model_name, 'roc_auc']:.4f}\")\n",
        "print(f\"  F1 Score: {results_df.loc[best_model_name, 'f1']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrices for best models\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "model_names = ['LR_Combined', 'RF_Interaction', 'RF_Combined']\n",
        "for idx, model_name in enumerate(model_names):\n",
        "    if model_name not in models:\n",
        "        continue\n",
        "    \n",
        "    model = models[model_name]\n",
        "    \n",
        "    if 'Combined' in model_name:\n",
        "        X_test = X_combined_test\n",
        "    elif 'Interaction' in model_name:\n",
        "        X_test = X_interaction_test\n",
        "    else:\n",
        "        X_test = X_baseline_test\n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    \n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
        "                xticklabels=['Safe', 'Adverse'], yticklabels=['Safe', 'Adverse'])\n",
        "    axes[idx].set_title(f'{model_name}\\nAccuracy: {results_df.loc[model_name, \"accuracy\"]:.3f}',\n",
        "                        fontsize=11, fontweight='bold')\n",
        "    axes[idx].set_ylabel('True Label')\n",
        "    axes[idx].set_xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary & Next Steps\n",
        "\n",
        "### Key Findings:\n",
        "1. **Feature Performance**: Which feature set works best?\n",
        "2. **Model Comparison**: LR vs RF performance\n",
        "3. **Important Features**: What drives predictions?\n",
        "\n",
        "### Next Steps for Full Model:\n",
        "1. **GNN Integration**: Use graph neural networks to capture complex interactions\n",
        "2. **More Disease Areas**: Expand to additional disease areas\n",
        "3. **External Data**: Integrate DisGeNET and DrugBank for richer gene mappings\n",
        "4. **Feature Engineering**: Add temporal, dosage, and patient-specific features\n",
        "5. **Evaluation**: Cross-validation, external validation sets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary & Next Steps\n",
        "\n",
        "### Key Findings:\n",
        "1. **Feature Performance**: Which feature set works best?\n",
        "2. **Model Comparison**: LR vs RF performance\n",
        "3. **Important Features**: What drives predictions?\n",
        "\n",
        "### Next Steps for Full Model:\n",
        "1. **GNN Integration**: Use graph neural networks to capture complex interactions\n",
        "2. **More Disease Areas**: Expand to additional disease areas\n",
        "3. **External Data**: Integrate DisGeNET and DrugBank for richer gene mappings\n",
        "4. **Feature Engineering**: Add temporal, dosage, and patient-specific features\n",
        "5. **Evaluation**: Cross-validation, external validation sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"=\" * 60)\n",
        "print(\"MVP SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nDataset:\")\n",
        "print(f\"  Disease areas: {len(selected_disease_ids)}\")\n",
        "print(f\"  Drugs: {len(selected_drug_ids)}\")\n",
        "print(f\"  Total examples: {len(df_dataset)}\")\n",
        "print(f\"    Positive (adverse): {df_dataset['label'].sum()}\")\n",
        "print(f\"    Negative (safe): {len(df_dataset) - df_dataset['label'].sum()}\")\n",
        "\n",
        "print(f\"\\nFeatures:\")\n",
        "print(f\"  Interaction features: {len(feature_cols)}\")\n",
        "print(f\"  Baseline features: {len(baseline_cols)}\")\n",
        "print(f\"  Combined: {len(feature_cols) + len(baseline_cols)}\")\n",
        "\n",
        "best_model_name = results_df['roc_auc'].idxmax()\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"  ROC-AUC: {results_df.loc[best_model_name, 'roc_auc']:.4f}\")\n",
        "print(f\"  Accuracy: {results_df.loc[best_model_name, 'accuracy']:.4f}\")\n",
        "print(f\"  F1 Score: {results_df.loc[best_model_name, 'f1']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
