{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP: Drug-Disease Adverse Outcome Prediction\n",
    "\n",
    "**Scope**: 1-2 disease areas, 10-20 drugs with known adverse outcomes, binary outcome prediction\n",
    "\n",
    "**Approach**:\n",
    "- **GDi**: Disease → Associated Genes (PrimeKG) → Pathways (PrimeKG)\n",
    "- **GDr**: Drugs → Target Genes (PrimeKG) → Pathways (PrimeKG)\n",
    "- **Features**: Shared genes, shared pathways, pathway overlap, graph distance\n",
    "- **Baseline**: Simple PrimeKG embeddings\n",
    "- **Models**: Logistic Regression & Random Forest (no GNNs yet)\n",
    "\n",
    "**Reference**: See `explore_primekg.ipynb` for PrimeKG dataset details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install pandas numpy networkx scikit-learn matplotlib seaborn tqdm requests node2vec -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Dependencies loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download PrimeKG\n",
    "\n",
    "PrimeKG is available from Harvard Dataverse. Reference: `explore_primekg.ipynb` for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at data/kg.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# PrimeKG download URL from Harvard Dataverse\n",
    "PRIMEKG_URL = \"https://dataverse.harvard.edu/api/access/datafile/6180620\"\n",
    "DATA_PATH = \"data/kg.csv\"  # Use full PrimeKG dataset (8.1M edges)\n",
    "\n",
    "def download_primekg(url, filepath, chunk_size=8192):\n",
    "    \"\"\"Download PrimeKG dataset with progress bar.\"\"\"\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"Dataset already exists at {filepath}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Downloading PrimeKG from {url}...\")\n",
    "    print(\"Note: This is ~1GB and may take several minutes.\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(filepath, 'wb') as f:\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Downloading\") as pbar:\n",
    "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "    \n",
    "    print(f\"Download complete! Saved to {filepath}\")\n",
    "\n",
    "# Download the dataset\n",
    "download_primekg(PRIMEKG_URL, DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load PrimeKG Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PrimeKG dataset...\n",
      "Dataset loaded: 8,100,498 edges, 12 columns\n",
      "Columns: ['relation', 'display_relation', 'x_index', 'x_id', 'x_type', 'x_name', 'x_source', 'y_index', 'y_id', 'y_type', 'y_name', 'y_source']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>display_relation</th>\n",
       "      <th>x_index</th>\n",
       "      <th>x_id</th>\n",
       "      <th>x_type</th>\n",
       "      <th>x_name</th>\n",
       "      <th>x_source</th>\n",
       "      <th>y_index</th>\n",
       "      <th>y_id</th>\n",
       "      <th>y_type</th>\n",
       "      <th>y_name</th>\n",
       "      <th>y_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>protein_protein</td>\n",
       "      <td>ppi</td>\n",
       "      <td>0</td>\n",
       "      <td>9796</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>PHYHIP</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>8889</td>\n",
       "      <td>56992</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>KIF15</td>\n",
       "      <td>NCBI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>protein_protein</td>\n",
       "      <td>ppi</td>\n",
       "      <td>1</td>\n",
       "      <td>7918</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>GPANK1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>2798</td>\n",
       "      <td>9240</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>PNMA1</td>\n",
       "      <td>NCBI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>protein_protein</td>\n",
       "      <td>ppi</td>\n",
       "      <td>2</td>\n",
       "      <td>8233</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>ZRSR2</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>5646</td>\n",
       "      <td>23548</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>TTC33</td>\n",
       "      <td>NCBI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>protein_protein</td>\n",
       "      <td>ppi</td>\n",
       "      <td>3</td>\n",
       "      <td>4899</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>NRF1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>11592</td>\n",
       "      <td>11253</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>MAN1B1</td>\n",
       "      <td>NCBI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>protein_protein</td>\n",
       "      <td>ppi</td>\n",
       "      <td>4</td>\n",
       "      <td>5297</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>PI4KA</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>2122</td>\n",
       "      <td>8601</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>RGS20</td>\n",
       "      <td>NCBI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          relation display_relation  x_index  x_id        x_type  x_name  \\\n",
       "0  protein_protein              ppi        0  9796  gene/protein  PHYHIP   \n",
       "1  protein_protein              ppi        1  7918  gene/protein  GPANK1   \n",
       "2  protein_protein              ppi        2  8233  gene/protein   ZRSR2   \n",
       "3  protein_protein              ppi        3  4899  gene/protein    NRF1   \n",
       "4  protein_protein              ppi        4  5297  gene/protein   PI4KA   \n",
       "\n",
       "  x_source  y_index   y_id        y_type  y_name y_source  \n",
       "0     NCBI     8889  56992  gene/protein   KIF15     NCBI  \n",
       "1     NCBI     2798   9240  gene/protein   PNMA1     NCBI  \n",
       "2     NCBI     5646  23548  gene/protein   TTC33     NCBI  \n",
       "3     NCBI    11592  11253  gene/protein  MAN1B1     NCBI  \n",
       "4     NCBI     2122   8601  gene/protein   RGS20     NCBI  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "print(\"Loading PrimeKG dataset...\")\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} edges, {df.shape[1]} columns\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select Disease Areas & Drugs with Adverse Outcomes\n",
    "\n",
    "We'll focus on diseases with contraindications (known adverse drug outcomes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total drug-disease edges: 85,262\n",
      "\n",
      "Relationship types:\n",
      "relation\n",
      "contraindication    61350\n",
      "indication          18776\n",
      "off-label use        5136\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract drug-disease relationships\n",
    "drug_disease_mask = (\n",
    "    ((df['x_type'] == 'drug') & (df['y_type'] == 'disease')) |\n",
    "    ((df['x_type'] == 'disease') & (df['y_type'] == 'drug'))\n",
    ")\n",
    "drug_disease_df = df[drug_disease_mask].copy()\n",
    "\n",
    "# Normalize direction: always drug -> disease\n",
    "def normalize_drug_disease(row):\n",
    "    if row['x_type'] == 'drug':\n",
    "        return pd.Series({\n",
    "            'drug_id': row['x_id'],\n",
    "            'drug_name': row['x_name'],\n",
    "            'disease_id': row['y_id'],\n",
    "            'disease_name': row['y_name'],\n",
    "            'relation': row['relation']\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({\n",
    "            'drug_id': row['y_id'],\n",
    "            'drug_name': row['y_name'],\n",
    "            'disease_id': row['x_id'],\n",
    "            'disease_name': row['x_name'],\n",
    "            'relation': row['relation']\n",
    "        })\n",
    "\n",
    "drug_disease_normalized = drug_disease_df.apply(normalize_drug_disease, axis=1)\n",
    "\n",
    "print(f\"Total drug-disease edges: {len(drug_disease_normalized):,}\")\n",
    "print(f\"\\nRelationship types:\")\n",
    "print(drug_disease_normalized['relation'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# EXPANDED DATASET: Select more diseases and drugs for reliable evaluation\n# Goal: 500+ examples with proper class balance\n\ncontraindications = drug_disease_normalized[drug_disease_normalized['relation'] == 'contraindication']\nindications = drug_disease_normalized[drug_disease_normalized['relation'] == 'indication']\n\n# Find diseases with BOTH contraindications AND indications\ndiseases_with_contra = set(contraindications['disease_id'])\ndiseases_with_indica = set(indications['disease_id'])\ndiseases_with_both = diseases_with_contra & diseases_with_indica\n\nprint(f\"Diseases with contraindications: {len(diseases_with_contra)}\")\nprint(f\"Diseases with indications: {len(diseases_with_indica)}\")\nprint(f\"Diseases with BOTH: {len(diseases_with_both)}\")\n\n# Get counts for diseases that have both relation types\ndisease_contra_counts = contraindications[contraindications['disease_id'].isin(diseases_with_both)].groupby(['disease_id', 'disease_name']).size().reset_index(name='contra_count')\ndisease_indica_counts = indications[indications['disease_id'].isin(diseases_with_both)].groupby(['disease_id', 'disease_name']).size().reset_index(name='indica_count')\n\n# Merge and compute balance ratio\ndisease_counts = disease_contra_counts.merge(disease_indica_counts[['disease_id', 'indica_count']], on='disease_id')\ndisease_counts['total'] = disease_counts['contra_count'] + disease_counts['indica_count']\ndisease_counts['balance_ratio'] = disease_counts[['contra_count', 'indica_count']].min(axis=1) / disease_counts[['contra_count', 'indica_count']].max(axis=1)\n\n# Sort by total edges but filter for reasonable balance (at least 20% minority class)\ndisease_counts_balanced = disease_counts[disease_counts['balance_ratio'] >= 0.2]\ndisease_counts_balanced = disease_counts_balanced.sort_values('total', ascending=False)\n\nprint(f\"\\nDiseases with good balance (>=20% minority): {len(disease_counts_balanced)}\")\nprint(\"\\nTop 15 balanced diseases:\")\nprint(disease_counts_balanced.head(15)[['disease_name', 'contra_count', 'indica_count', 'total', 'balance_ratio']].to_string(index=False))\n\n# SELECT 10 DISEASES (expanded from 2)\nN_DISEASES = 10\nselected_diseases = disease_counts_balanced.head(N_DISEASES)\nselected_disease_ids = selected_diseases['disease_id'].tolist()\nselected_disease_names = selected_diseases['disease_name'].tolist()\n\nprint(f\"\\n{'='*60}\")\nprint(f\"SELECTED {len(selected_disease_ids)} DISEASE AREAS:\")\nprint(f\"{'='*60}\")\nfor did, dname in zip(selected_disease_ids, selected_disease_names):\n    row = disease_counts[disease_counts['disease_id'] == did].iloc[0]\n    print(f\"  • {dname}: {int(row['contra_count'])} contras, {int(row['indica_count'])} indics\")\n\n# Get ALL drugs that have relationships with selected diseases\nselected_contra = contraindications[contraindications['disease_id'].isin(selected_disease_ids)]\nselected_indica = indications[indications['disease_id'].isin(selected_disease_ids)]\n\nall_drugs_contra = set(selected_contra['drug_id'])\nall_drugs_indica = set(selected_indica['drug_id'])\nall_drugs = all_drugs_contra | all_drugs_indica\n\nprint(f\"\\nDrugs with contraindications for selected diseases: {len(all_drugs_contra)}\")\nprint(f\"Drugs with indications for selected diseases: {len(all_drugs_indica)}\")\nprint(f\"Total unique drugs: {len(all_drugs)}\")\n\n# Get drug counts\ndrug_contra_counts = selected_contra.groupby(['drug_id', 'drug_name']).size().reset_index(name='contra_count')\ndrug_indica_counts = selected_indica.groupby(['drug_id', 'drug_name']).size().reset_index(name='indica_count')\n\ndrug_counts = drug_contra_counts.merge(drug_indica_counts[['drug_id', 'indica_count']], on='drug_id', how='outer').fillna(0)\ndrug_counts['total'] = drug_counts['contra_count'] + drug_counts['indica_count']\ndrug_counts = drug_counts.sort_values('total', ascending=False)\n\n# SELECT TOP 100 DRUGS (expanded from 20)\nN_DRUGS = 100\nselected_drugs = drug_counts.head(N_DRUGS)\nselected_drug_ids = selected_drugs['drug_id'].tolist()\nselected_drug_names = selected_drugs['drug_name'].tolist()\n\nprint(f\"\\n{'='*60}\")\nprint(f\"SELECTED {len(selected_drug_ids)} DRUGS:\")\nprint(f\"{'='*60}\")\nprint(f\"Top 10 drugs by total relationships:\")\nfor i, (did, dname) in enumerate(zip(selected_drug_ids[:10], selected_drug_names[:10])):\n    row = drug_counts[drug_counts['drug_id'] == did].iloc[0]\n    print(f\"  {i+1}. {dname}: {int(row['contra_count'])} contras, {int(row['indica_count'])} indics\")\nprint(f\"  ... and {len(selected_drug_ids) - 10} more drugs\")\n\n# Preview expected dataset size\nexpected_positive = len(selected_contra[\n    (selected_contra['disease_id'].isin(selected_disease_ids)) &\n    (selected_contra['drug_id'].isin(selected_drug_ids))\n])\nexpected_negative = len(selected_indica[\n    (selected_indica['disease_id'].isin(selected_disease_ids)) &\n    (selected_indica['drug_id'].isin(selected_drug_ids))\n])\n\nprint(f\"\\n{'='*60}\")\nprint(f\"EXPECTED DATASET SIZE:\")\nprint(f\"{'='*60}\")\nprint(f\"  Positive (contraindications): ~{expected_positive}\")\nprint(f\"  Negative (indications): ~{expected_negative}\")\nprint(f\"  Total: ~{expected_positive + expected_negative}\")\nprint(f\"  Class balance: {min(expected_positive, expected_negative) / max(expected_positive, expected_negative):.1%}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build GDi and GDr Mappings\n",
    "\n",
    "**GDi**: Disease → Genes → Pathways  \n",
    "**GDr**: Drug → Target Genes → Pathways\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building GDi: Disease → Genes → Pathways\n",
      "============================================================\n",
      "Diseases with gene associations: 5593\n",
      "Genes with pathway associations: 10849\n",
      "Diseases with pathway associations: 5123\n",
      "\n",
      "hypertension:\n",
      "  Genes: 16, Pathways: 74\n",
      "\n",
      "hypertensive disorder:\n",
      "  Genes: 12, Pathways: 59\n"
     ]
    }
   ],
   "source": [
    "# Build GDi: Disease → Genes → Pathways\n",
    "print(\"Building GDi: Disease → Genes → Pathways\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Disease → Genes (disease_protein relation)\n",
    "disease_gene_edges = df[\n",
    "    ((df['x_type'] == 'disease') & (df['y_type'] == 'gene/protein') & (df['relation'] == 'disease_protein')) |\n",
    "    ((df['x_type'] == 'gene/protein') & (df['y_type'] == 'disease') & (df['relation'] == 'disease_protein'))\n",
    "].copy()\n",
    "\n",
    "# Normalize to disease -> gene\n",
    "def normalize_disease_gene(row):\n",
    "    if row['x_type'] == 'disease':\n",
    "        return pd.Series({\n",
    "            'disease_id': row['x_id'],\n",
    "            'disease_name': row['x_name'],\n",
    "            'gene_id': row['y_id'],\n",
    "            'gene_name': row['y_name']\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({\n",
    "            'disease_id': row['y_id'],\n",
    "            'disease_name': row['y_name'],\n",
    "            'gene_id': row['x_id'],\n",
    "            'gene_name': row['x_name']\n",
    "        })\n",
    "\n",
    "disease_gene_df = disease_gene_edges.apply(normalize_disease_gene, axis=1)\n",
    "\n",
    "# Step 2: Genes → Pathways (pathway_protein relation)\n",
    "gene_pathway_edges = df[\n",
    "    ((df['x_type'] == 'gene/protein') & (df['y_type'] == 'pathway') & (df['relation'] == 'pathway_protein')) |\n",
    "    ((df['x_type'] == 'pathway') & (df['y_type'] == 'gene/protein') & (df['relation'] == 'pathway_protein'))\n",
    "].copy()\n",
    "\n",
    "def normalize_gene_pathway(row):\n",
    "    if row['x_type'] == 'gene/protein':\n",
    "        return pd.Series({\n",
    "            'gene_id': row['x_id'],\n",
    "            'gene_name': row['x_name'],\n",
    "            'pathway_id': row['y_id'],\n",
    "            'pathway_name': row['y_name']\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({\n",
    "            'gene_id': row['y_id'],\n",
    "            'gene_name': row['y_name'],\n",
    "            'pathway_id': row['x_id'],\n",
    "            'pathway_name': row['x_name']\n",
    "        })\n",
    "\n",
    "gene_pathway_df = gene_pathway_edges.apply(normalize_gene_pathway, axis=1)\n",
    "\n",
    "# Build GDi mapping: disease_id -> {gene_ids} -> {pathway_ids}\n",
    "gdi_disease_genes = defaultdict(set)\n",
    "gdi_gene_pathways = defaultdict(set)\n",
    "gdi_disease_pathways = defaultdict(set)\n",
    "\n",
    "# Disease -> Genes\n",
    "for _, row in disease_gene_df.iterrows():\n",
    "    gdi_disease_genes[row['disease_id']].add(row['gene_id'])\n",
    "\n",
    "# Gene -> Pathways\n",
    "for _, row in gene_pathway_df.iterrows():\n",
    "    gdi_gene_pathways[row['gene_id']].add(row['pathway_id'])\n",
    "\n",
    "# Disease -> Pathways (via genes)\n",
    "for disease_id, gene_ids in gdi_disease_genes.items():\n",
    "    for gene_id in gene_ids:\n",
    "        if gene_id in gdi_gene_pathways:\n",
    "            gdi_disease_pathways[disease_id].update(gdi_gene_pathways[gene_id])\n",
    "\n",
    "print(f\"Diseases with gene associations: {len(gdi_disease_genes)}\")\n",
    "print(f\"Genes with pathway associations: {len(gdi_gene_pathways)}\")\n",
    "print(f\"Diseases with pathway associations: {len(gdi_disease_pathways)}\")\n",
    "\n",
    "# Check selected diseases\n",
    "for disease_id in selected_disease_ids:\n",
    "    n_genes = len(gdi_disease_genes.get(disease_id, set()))\n",
    "    n_pathways = len(gdi_disease_pathways.get(disease_id, set()))\n",
    "    disease_name = selected_diseases[selected_diseases['disease_id'] == disease_id]['disease_name'].values[0]\n",
    "    print(f\"\\n{disease_name}:\")\n",
    "    print(f\"  Genes: {n_genes}, Pathways: {n_pathways}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building GDr: Drug → Target Genes → Pathways\n",
      "============================================================\n",
      "Drugs with gene targets: 6282\n",
      "Drugs with pathway associations: 6131\n",
      "\n",
      "Leuprolide:\n",
      "  Target Genes: 1, Pathways: 2\n",
      "\n",
      "Ephedrine:\n",
      "  Target Genes: 8, Pathways: 26\n",
      "\n",
      "Difenoxin:\n",
      "  Target Genes: 0, Pathways: 0\n",
      "\n",
      "Phenazopyridine:\n",
      "  Target Genes: 1, Pathways: 2\n",
      "\n",
      "Antipyrine:\n",
      "  Target Genes: 13, Pathways: 22\n"
     ]
    }
   ],
   "source": [
    "# Build GDr: Drug → Target Genes → Pathways\n",
    "print(\"Building GDr: Drug → Target Genes → Pathways\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Drug → Target Genes (drug_protein relation)\n",
    "drug_gene_edges = df[\n",
    "    ((df['x_type'] == 'drug') & (df['y_type'] == 'gene/protein') & (df['relation'] == 'drug_protein')) |\n",
    "    ((df['x_type'] == 'gene/protein') & (df['y_type'] == 'drug') & (df['relation'] == 'drug_protein'))\n",
    "].copy()\n",
    "\n",
    "def normalize_drug_gene(row):\n",
    "    if row['x_type'] == 'drug':\n",
    "        return pd.Series({\n",
    "            'drug_id': row['x_id'],\n",
    "            'drug_name': row['x_name'],\n",
    "            'gene_id': row['y_id'],\n",
    "            'gene_name': row['y_name']\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({\n",
    "            'drug_id': row['y_id'],\n",
    "            'drug_name': row['y_name'],\n",
    "            'gene_id': row['x_id'],\n",
    "            'gene_name': row['x_name']\n",
    "        })\n",
    "\n",
    "drug_gene_df = drug_gene_edges.apply(normalize_drug_gene, axis=1)\n",
    "\n",
    "# Build GDr mapping: drug_id -> {gene_ids} -> {pathway_ids}\n",
    "gdr_drug_genes = defaultdict(set)\n",
    "gdr_drug_pathways = defaultdict(set)\n",
    "\n",
    "# Drug -> Genes\n",
    "for _, row in drug_gene_df.iterrows():\n",
    "    gdr_drug_genes[row['drug_id']].add(row['gene_id'])\n",
    "\n",
    "# Drug -> Pathways (via genes, reuse gene_pathway mapping)\n",
    "for drug_id, gene_ids in gdr_drug_genes.items():\n",
    "    for gene_id in gene_ids:\n",
    "        if gene_id in gdi_gene_pathways:\n",
    "            gdr_drug_pathways[drug_id].update(gdi_gene_pathways[gene_id])\n",
    "\n",
    "print(f\"Drugs with gene targets: {len(gdr_drug_genes)}\")\n",
    "print(f\"Drugs with pathway associations: {len(gdr_drug_pathways)}\")\n",
    "\n",
    "# Check selected drugs\n",
    "for drug_id in selected_drug_ids[:5]:\n",
    "    n_genes = len(gdr_drug_genes.get(drug_id, set()))\n",
    "    n_pathways = len(gdr_drug_pathways.get(drug_id, set()))\n",
    "    drug_name = selected_drugs[selected_drugs['drug_id'] == drug_id]['drug_name'].values[0]\n",
    "    print(f\"\\n{drug_name}:\")\n",
    "    print(f\"  Target Genes: {n_genes}, Pathways: {n_pathways}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build NetworkX Graph for Distance Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NetworkX graph for distance computation...\n",
      "Graph built: 273 nodes, 393 edges\n",
      "  Diseases: 2\n",
      "  Drugs: 20\n",
      "  Genes: 66\n",
      "  Pathways: 185\n"
     ]
    }
   ],
   "source": [
    "# Build a simplified NetworkX graph for computing distances\n",
    "# We'll include: drugs, diseases, genes, pathways\n",
    "print(\"Building NetworkX graph for distance computation...\")\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with types\n",
    "node_info = {}\n",
    "\n",
    "# Add disease nodes\n",
    "for disease_id in selected_disease_ids:\n",
    "    G.add_node(disease_id, node_type='disease')\n",
    "    disease_name = selected_diseases[selected_diseases['disease_id'] == disease_id]['disease_name'].values[0]\n",
    "    node_info[disease_id] = {'name': disease_name, 'type': 'disease'}\n",
    "\n",
    "# Add drug nodes\n",
    "for drug_id in selected_drug_ids:\n",
    "    G.add_node(drug_id, node_type='drug')\n",
    "    drug_name = selected_drugs[selected_drugs['drug_id'] == drug_id]['drug_name'].values[0]\n",
    "    node_info[drug_id] = {'name': drug_name, 'type': 'drug'}\n",
    "\n",
    "# Add gene nodes and edges\n",
    "all_genes = set()\n",
    "for disease_id in selected_disease_ids:\n",
    "    all_genes.update(gdi_disease_genes.get(disease_id, set()))\n",
    "for drug_id in selected_drug_ids:\n",
    "    all_genes.update(gdr_drug_genes.get(drug_id, set()))\n",
    "\n",
    "for gene_id in all_genes:\n",
    "    G.add_node(gene_id, node_type='gene')\n",
    "    node_info[gene_id] = {'name': f'Gene_{gene_id}', 'type': 'gene'}\n",
    "\n",
    "# Add pathway nodes\n",
    "all_pathways = set()\n",
    "for disease_id in selected_disease_ids:\n",
    "    all_pathways.update(gdi_disease_pathways.get(disease_id, set()))\n",
    "for drug_id in selected_drug_ids:\n",
    "    all_pathways.update(gdr_drug_pathways.get(drug_id, set()))\n",
    "\n",
    "for pathway_id in all_pathways:\n",
    "    G.add_node(pathway_id, node_type='pathway')\n",
    "    node_info[pathway_id] = {'name': f'Pathway_{pathway_id}', 'type': 'pathway'}\n",
    "\n",
    "# Add edges: disease-gene, drug-gene, gene-pathway\n",
    "for disease_id in selected_disease_ids:\n",
    "    for gene_id in gdi_disease_genes.get(disease_id, set()):\n",
    "        G.add_edge(disease_id, gene_id, relation='disease_gene')\n",
    "\n",
    "for drug_id in selected_drug_ids:\n",
    "    for gene_id in gdr_drug_genes.get(drug_id, set()):\n",
    "        G.add_edge(drug_id, gene_id, relation='drug_gene')\n",
    "\n",
    "for gene_id in all_genes:\n",
    "    for pathway_id in gdi_gene_pathways.get(gene_id, set()):\n",
    "        if pathway_id in all_pathways:\n",
    "            G.add_edge(gene_id, pathway_id, relation='gene_pathway')\n",
    "\n",
    "print(f\"Graph built: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"  Diseases: {len(selected_disease_ids)}\")\n",
    "print(f\"  Drugs: {len(selected_drug_ids)}\")\n",
    "print(f\"  Genes: {len(all_genes)}\")\n",
    "print(f\"  Pathways: {len(all_pathways)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Interaction Features\n",
    "\n",
    "For each drug-disease pair, extract:\n",
    "1. Shared genes count\n",
    "2. Shared pathways count\n",
    "3. Pathway coverage overlap (Jaccard similarity)\n",
    "4. Graph distance between drug and disease nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pathway_overlap(disease_pathways, drug_pathways):\n",
    "    \"\"\"Compute Jaccard similarity of pathway sets.\"\"\"\n",
    "    if len(disease_pathways) == 0 and len(drug_pathways) == 0:\n",
    "        return 0.0\n",
    "    intersection = len(disease_pathways & drug_pathways)\n",
    "    union = len(disease_pathways | drug_pathways)\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def compute_graph_distance(G, drug_id, disease_id):\n",
    "    \"\"\"Compute shortest path distance between drug and disease.\"\"\"\n",
    "    try:\n",
    "        if drug_id not in G or disease_id not in G:\n",
    "            return -1  # Not in graph\n",
    "        distance = nx.shortest_path_length(G, drug_id, disease_id)\n",
    "        return distance\n",
    "    except nx.NetworkXNoPath:\n",
    "        return -1  # No path exists\n",
    "\n",
    "def extract_features(drug_id, disease_id, gdi_disease_genes, gdi_disease_pathways,\n",
    "                     gdr_drug_genes, gdr_drug_pathways, G):\n",
    "    \"\"\"Extract all interaction features for a drug-disease pair.\"\"\"\n",
    "    # Get gene and pathway sets\n",
    "    disease_genes = gdi_disease_genes.get(disease_id, set())\n",
    "    disease_pathways = gdi_disease_pathways.get(disease_id, set())\n",
    "    drug_genes = gdr_drug_genes.get(drug_id, set())\n",
    "    drug_pathways = gdr_drug_pathways.get(drug_id, set())\n",
    "    \n",
    "    # Feature 1: Shared genes count\n",
    "    shared_genes = disease_genes & drug_genes\n",
    "    n_shared_genes = len(shared_genes)\n",
    "    \n",
    "    # Feature 2: Shared pathways count\n",
    "    shared_pathways = disease_pathways & drug_pathways\n",
    "    n_shared_pathways = len(shared_pathways)\n",
    "    \n",
    "    # Feature 3: Pathway overlap (Jaccard similarity)\n",
    "    pathway_overlap = compute_pathway_overlap(disease_pathways, drug_pathways)\n",
    "    \n",
    "    # Feature 4: Graph distance\n",
    "    graph_distance = compute_graph_distance(G, drug_id, disease_id)\n",
    "    \n",
    "    # Additional features\n",
    "    n_disease_genes = len(disease_genes)\n",
    "    n_disease_pathways = len(disease_pathways)\n",
    "    n_drug_genes = len(drug_genes)\n",
    "    n_drug_pathways = len(drug_pathways)\n",
    "    \n",
    "    return {\n",
    "        'n_shared_genes': n_shared_genes,\n",
    "        'n_shared_pathways': n_shared_pathways,\n",
    "        'pathway_overlap': pathway_overlap,\n",
    "        'graph_distance': graph_distance,\n",
    "        'n_disease_genes': n_disease_genes,\n",
    "        'n_disease_pathways': n_disease_pathways,\n",
    "        'n_drug_genes': n_drug_genes,\n",
    "        'n_drug_pathways': n_drug_pathways,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with features...\n",
      "Positive examples (contraindications): 80\n",
      "Negative examples (indications): 0\n",
      "\n",
      "WARNING: No indication pairs found for selected drugs/diseases.\n",
      "Expanding to include all indications for selected diseases...\n",
      "Expanded negative examples: 412\n",
      "\n",
      "Balancing: undersampling negative pairs from 412 to 80\n",
      "\n",
      "Final dataset balance:\n",
      "  Positive (contraindications): 80\n",
      "  Negative (indications): 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Positive pairs: 100%|██████████| 80/80 [00:00<00:00, 13942.67it/s]\n",
      "Negative pairs: 100%|██████████| 80/80 [00:00<00:00, 25031.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset created: 160 examples\n",
      "  Positive (contraindication): 80\n",
      "  Negative (indication): 80\n",
      "\n",
      "Feature statistics:\n",
      "       n_shared_genes  n_shared_pathways  pathway_overlap  graph_distance  \\\n",
      "count      160.000000         160.000000       160.000000       160.00000   \n",
      "mean         0.081250           3.162500         0.037785         0.95000   \n",
      "std          0.274076           3.569415         0.034134         2.41536   \n",
      "min          0.000000           0.000000         0.000000        -1.00000   \n",
      "25%          0.000000           1.000000         0.013158        -1.00000   \n",
      "50%          0.000000           2.500000         0.033521        -1.00000   \n",
      "75%          0.000000           5.000000         0.057809         4.00000   \n",
      "max          1.000000          25.000000         0.195312         4.00000   \n",
      "\n",
      "       n_disease_genes  n_disease_pathways  n_drug_genes  n_drug_pathways  \\\n",
      "count       160.000000          160.000000     160.00000       160.000000   \n",
      "mean         14.000000           66.500000       4.88750        13.393750   \n",
      "std           2.006279            7.523548       6.46421        14.950273   \n",
      "min          12.000000           59.000000       0.00000         0.000000   \n",
      "25%          12.000000           59.000000       1.75000         3.000000   \n",
      "50%          14.000000           66.500000       3.00000        11.000000   \n",
      "75%          16.000000           74.000000       6.00000        18.000000   \n",
      "max          16.000000           74.000000      46.00000        85.000000   \n",
      "\n",
      "           label  \n",
      "count  160.00000  \n",
      "mean     0.50000  \n",
      "std      0.50157  \n",
      "min      0.00000  \n",
      "25%      0.00000  \n",
      "50%      0.50000  \n",
      "75%      1.00000  \n",
      "max      1.00000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dataset: all drug-disease pairs with labels and features\n",
    "print(\"Creating dataset with features...\")\n",
    "\n",
    "dataset = []\n",
    "\n",
    "# Positive examples: contraindications (adverse outcomes)\n",
    "positive_pairs = contraindications[\n",
    "    (contraindications['disease_id'].isin(selected_disease_ids)) &\n",
    "    (contraindications['drug_id'].isin(selected_drug_ids))\n",
    "]\n",
    "\n",
    "print(f\"Positive examples (contraindications): {len(positive_pairs)}\")\n",
    "\n",
    "# Negative examples: indications (therapeutic uses) for the same drugs/diseases\n",
    "negative_pairs = indications[\n",
    "    (indications['disease_id'].isin(selected_disease_ids)) &\n",
    "    (indications['drug_id'].isin(selected_drug_ids))\n",
    "]\n",
    "\n",
    "print(f\"Negative examples (indications): {len(negative_pairs)}\")\n",
    "\n",
    "# Validate we have both classes\n",
    "if len(positive_pairs) == 0:\n",
    "    raise ValueError(\"No positive samples found! Check disease/drug selection.\")\n",
    "if len(negative_pairs) == 0:\n",
    "    print(\"\\nWARNING: No indication pairs found for selected drugs/diseases.\")\n",
    "    print(\"Expanding to include all indications for selected diseases...\")\n",
    "    # Fallback: use any drug with indications for selected diseases\n",
    "    negative_pairs = indications[indications['disease_id'].isin(selected_disease_ids)]\n",
    "    print(f\"Expanded negative examples: {len(negative_pairs)}\")\n",
    "\n",
    "if len(negative_pairs) == 0:\n",
    "    raise ValueError(\"No negative samples found! Select different diseases that have both contraindications AND indications.\")\n",
    "\n",
    "# Balance the dataset if needed (undersample majority class)\n",
    "min_samples = min(len(positive_pairs), len(negative_pairs))\n",
    "if len(positive_pairs) > 2 * len(negative_pairs):\n",
    "    print(f\"\\nBalancing: undersampling positive pairs from {len(positive_pairs)} to {len(negative_pairs)}\")\n",
    "    positive_pairs = positive_pairs.sample(n=len(negative_pairs), random_state=42)\n",
    "elif len(negative_pairs) > 2 * len(positive_pairs):\n",
    "    print(f\"\\nBalancing: undersampling negative pairs from {len(negative_pairs)} to {len(positive_pairs)}\")\n",
    "    negative_pairs = negative_pairs.sample(n=len(positive_pairs), random_state=42)\n",
    "\n",
    "print(f\"\\nFinal dataset balance:\")\n",
    "print(f\"  Positive (contraindications): {len(positive_pairs)}\")\n",
    "print(f\"  Negative (indications): {len(negative_pairs)}\")\n",
    "\n",
    "# Extract features for positive pairs\n",
    "for _, row in tqdm(positive_pairs.iterrows(), total=len(positive_pairs), desc=\"Positive pairs\"):\n",
    "    features = extract_features(\n",
    "        row['drug_id'], row['disease_id'],\n",
    "        gdi_disease_genes, gdi_disease_pathways,\n",
    "        gdr_drug_genes, gdr_drug_pathways, G\n",
    "    )\n",
    "    features['drug_id'] = row['drug_id']\n",
    "    features['drug_name'] = row['drug_name']\n",
    "    features['disease_id'] = row['disease_id']\n",
    "    features['disease_name'] = row['disease_name']\n",
    "    features['label'] = 1  # Adverse outcome (contraindication)\n",
    "    dataset.append(features)\n",
    "\n",
    "# Extract features for negative pairs\n",
    "for _, row in tqdm(negative_pairs.iterrows(), total=len(negative_pairs), desc=\"Negative pairs\"):\n",
    "    features = extract_features(\n",
    "        row['drug_id'], row['disease_id'],\n",
    "        gdi_disease_genes, gdi_disease_pathways,\n",
    "        gdr_drug_genes, gdr_drug_pathways, G\n",
    "    )\n",
    "    features['drug_id'] = row['drug_id']\n",
    "    features['drug_name'] = row['drug_name']\n",
    "    features['disease_id'] = row['disease_id']\n",
    "    features['disease_name'] = row['disease_name']\n",
    "    features['label'] = 0  # Therapeutic use (indication)\n",
    "    dataset.append(features)\n",
    "\n",
    "df_dataset = pd.DataFrame(dataset)\n",
    "\n",
    "print(f\"\\nDataset created: {len(df_dataset)} examples\")\n",
    "print(f\"  Positive (contraindication): {df_dataset['label'].sum()}\")\n",
    "print(f\"  Negative (indication): {len(df_dataset) - df_dataset['label'].sum()}\")\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(df_dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Baseline: Simple PrimeKG Embeddings\n",
    "\n",
    "Create simple node embeddings using graph structure (e.g., node2vec or degree-based features).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating baseline embeddings...\n",
      "Computing centrality measures...\n",
      "Baseline features created: 8 features\n",
      "       drug_degree  disease_degree  drug_betweenness  disease_betweenness  \\\n",
      "count   160.000000      160.000000        160.000000           160.000000   \n",
      "mean      1.800000       14.000000          0.010867             0.130643   \n",
      "std       2.960537        2.006279          0.025219             0.051868   \n",
      "min       0.000000       12.000000          0.000000             0.078938   \n",
      "25%       0.000000       12.000000          0.000000             0.078938   \n",
      "50%       0.000000       14.000000          0.000000             0.130643   \n",
      "75%       3.000000       16.000000          0.005857             0.182349   \n",
      "max      13.000000       16.000000          0.114912             0.182349   \n",
      "\n",
      "       drug_closeness  disease_closeness  degree_sum  degree_diff  \n",
      "count      160.000000         160.000000  160.000000   160.000000  \n",
      "mean         0.075299           0.257807   15.800000    12.225000  \n",
      "std          0.090617           0.008590    3.576302     3.489337  \n",
      "min          0.000000           0.249244   12.000000     1.000000  \n",
      "25%          0.000000           0.249244   12.000000    11.000000  \n",
      "50%          0.000000           0.257807   16.000000    12.000000  \n",
      "75%          0.174674           0.266370   17.000000    16.000000  \n",
      "max          0.211797           0.266370   29.000000    16.000000  \n"
     ]
    }
   ],
   "source": [
    "# Simple baseline: Use node degrees and centrality measures as embeddings\n",
    "print(\"Creating baseline embeddings...\")\n",
    "\n",
    "# Compute node degrees\n",
    "degrees = dict(G.degree())\n",
    "\n",
    "# Compute centrality measures (for a subset if graph is large)\n",
    "if G.number_of_nodes() < 10000:\n",
    "    print(\"Computing centrality measures...\")\n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "    closeness = nx.closeness_centrality(G)\n",
    "else:\n",
    "    print(\"Graph too large, using degree only...\")\n",
    "    betweenness = {n: 0.0 for n in G.nodes()}\n",
    "    closeness = {n: 0.0 for n in G.nodes()}\n",
    "\n",
    "# Create embedding features for each drug-disease pair\n",
    "baseline_features = []\n",
    "for _, row in df_dataset.iterrows():\n",
    "    drug_id = row['drug_id']\n",
    "    disease_id = row['disease_id']\n",
    "    \n",
    "    drug_degree = degrees.get(drug_id, 0)\n",
    "    disease_degree = degrees.get(disease_id, 0)\n",
    "    drug_betweenness = betweenness.get(drug_id, 0.0)\n",
    "    disease_betweenness = betweenness.get(disease_id, 0.0)\n",
    "    drug_closeness = closeness.get(drug_id, 0.0)\n",
    "    disease_closeness = closeness.get(disease_id, 0.0)\n",
    "    \n",
    "    baseline_features.append({\n",
    "        'drug_degree': drug_degree,\n",
    "        'disease_degree': disease_degree,\n",
    "        'drug_betweenness': drug_betweenness,\n",
    "        'disease_betweenness': disease_betweenness,\n",
    "        'drug_closeness': drug_closeness,\n",
    "        'disease_closeness': disease_closeness,\n",
    "        'degree_sum': drug_degree + disease_degree,\n",
    "        'degree_diff': abs(drug_degree - disease_degree),\n",
    "    })\n",
    "\n",
    "df_baseline = pd.DataFrame(baseline_features)\n",
    "print(f\"Baseline features created: {df_baseline.shape[1]} features\")\n",
    "print(df_baseline.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train Models\n",
    "\n",
    "Train Logistic Regression and Random Forest models on:\n",
    "1. Interaction features only\n",
    "2. Baseline embeddings only\n",
    "3. Combined features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare feature sets with CROSS-VALIDATION for reliable evaluation\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\n\n# Define feature columns - EXCLUDE graph_distance (potential leakage)\nfeature_cols_safe = [\n    'n_shared_genes', 'n_shared_pathways', 'pathway_overlap',\n    'n_disease_genes', 'n_disease_pathways', 'n_drug_genes', 'n_drug_pathways'\n]\n\n# Also test with graph_distance to see if it causes leakage\nfeature_cols_with_distance = feature_cols_safe + ['graph_distance']\n\nbaseline_cols = list(df_baseline.columns)\n\n# Handle missing values (graph_distance = -1 means no path)\nmax_distance = df_dataset['graph_distance'].replace(-1, np.nan).max()\ndf_dataset['graph_distance'] = df_dataset['graph_distance'].replace(-1, max_distance + 1 if not np.isnan(max_distance) else 10)\n\n# Prepare feature matrices\nX_interaction_safe = df_dataset[feature_cols_safe].values\nX_interaction_full = df_dataset[feature_cols_with_distance].values\nX_baseline = df_baseline.values\nX_combined_safe = np.hstack([X_interaction_safe, X_baseline])\nX_combined_full = np.hstack([X_interaction_full, X_baseline])\n\ny = df_dataset['label'].values\n\nprint(f\"{'='*60}\")\nprint(\"DATASET SUMMARY\")\nprint(f\"{'='*60}\")\nprint(f\"Total samples: {len(y)}\")\nprint(f\"Positive (contraindication): {y.sum()} ({100*y.mean():.1f}%)\")\nprint(f\"Negative (indication): {len(y) - y.sum()} ({100*(1-y.mean()):.1f}%)\")\nprint(f\"\\nFeature sets:\")\nprint(f\"  Interaction (safe): {X_interaction_safe.shape[1]} features\")\nprint(f\"  Interaction (with distance): {X_interaction_full.shape[1]} features\")\nprint(f\"  Baseline: {X_baseline.shape[1]} features\")\nprint(f\"  Combined (safe): {X_combined_safe.shape[1]} features\")\n\n# Setup cross-validation\nN_FOLDS = 5\ncv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n\nprint(f\"\\nUsing {N_FOLDS}-fold stratified cross-validation\")\nprint(f\"Each fold: ~{len(y)//N_FOLDS} test samples (much better than 8!)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train models with CROSS-VALIDATION for reliable metrics\nprint(\"Training models with 5-fold cross-validation...\")\nprint(\"=\" * 60)\n\ndef evaluate_model_cv(model, X, y, cv, name):\n    \"\"\"Evaluate model using cross-validation and return metrics.\"\"\"\n    # Multiple metrics\n    accuracy = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n    roc_auc = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')\n    f1 = cross_val_score(model, X, y, cv=cv, scoring='f1')\n    precision = cross_val_score(model, X, y, cv=cv, scoring='precision')\n    recall = cross_val_score(model, X, y, cv=cv, scoring='recall')\n    \n    return {\n        'accuracy_mean': accuracy.mean(),\n        'accuracy_std': accuracy.std(),\n        'roc_auc_mean': roc_auc.mean(),\n        'roc_auc_std': roc_auc.std(),\n        'f1_mean': f1.mean(),\n        'f1_std': f1.std(),\n        'precision_mean': precision.mean(),\n        'recall_mean': recall.mean(),\n    }\n\nresults = {}\n\n# Define all experiments\nexperiments = [\n    # Logistic Regression experiments\n    ('LR_Interaction_Safe', LogisticRegression(random_state=42, max_iter=1000), X_interaction_safe),\n    ('LR_Interaction_Full', LogisticRegression(random_state=42, max_iter=1000), X_interaction_full),\n    ('LR_Baseline', LogisticRegression(random_state=42, max_iter=1000), X_baseline),\n    ('LR_Combined_Safe', LogisticRegression(random_state=42, max_iter=1000), X_combined_safe),\n    ('LR_Combined_Full', LogisticRegression(random_state=42, max_iter=1000), X_combined_full),\n    # Random Forest experiments\n    ('RF_Interaction_Safe', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1), X_interaction_safe),\n    ('RF_Interaction_Full', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1), X_interaction_full),\n    ('RF_Baseline', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1), X_baseline),\n    ('RF_Combined_Safe', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1), X_combined_safe),\n    ('RF_Combined_Full', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1), X_combined_full),\n]\n\nprint(f\"\\nRunning {len(experiments)} experiments...\")\nprint(\"-\" * 60)\n\nfor name, model, X in experiments:\n    print(f\"  {name}...\", end=\" \")\n    results[name] = evaluate_model_cv(model, X, y, cv, name)\n    print(f\"ROC-AUC: {results[name]['roc_auc_mean']:.3f} ± {results[name]['roc_auc_std']:.3f}\")\n\n# Create results DataFrame\nresults_df = pd.DataFrame(results).T\nresults_df = results_df.sort_values('roc_auc_mean', ascending=False)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"CROSS-VALIDATION RESULTS (sorted by ROC-AUC)\")\nprint(\"=\" * 60)\nprint(\"\\n{:<25} {:>12} {:>12} {:>12}\".format(\"Model\", \"ROC-AUC\", \"Accuracy\", \"F1\"))\nprint(\"-\" * 60)\nfor idx, row in results_df.iterrows():\n    print(\"{:<25} {:>5.3f}±{:.3f} {:>5.3f}±{:.3f} {:>5.3f}±{:.3f}\".format(\n        idx,\n        row['roc_auc_mean'], row['roc_auc_std'],\n        row['accuracy_mean'], row['accuracy_std'],\n        row['f1_mean'], row['f1_std']\n    ))\n\n# Check for leakage: compare _Safe vs _Full versions\nprint(\"\\n\" + \"=\" * 60)\nprint(\"LEAKAGE CHECK: Does graph_distance inflate scores?\")\nprint(\"=\" * 60)\nfor model_type in ['LR', 'RF']:\n    for feature_type in ['Interaction', 'Combined']:\n        safe_name = f\"{model_type}_{feature_type}_Safe\"\n        full_name = f\"{model_type}_{feature_type}_Full\"\n        if safe_name in results and full_name in results:\n            diff = results[full_name]['roc_auc_mean'] - results[safe_name]['roc_auc_mean']\n            indicator = \"⚠️ POSSIBLE LEAKAGE\" if diff > 0.05 else \"✓ OK\"\n            print(f\"  {feature_type} ({model_type}): {diff:+.3f} {indicator}\")"
  },
  {
   "cell_type": "code",
   "source": "# DISEASE-LEVEL CROSS-VALIDATION\n# This tests TRUE generalization: Can the model predict for UNSEEN diseases?\nprint(\"=\" * 60)\nprint(\"DISEASE-LEVEL CROSS-VALIDATION (Leave-One-Disease-Out)\")\nprint(\"=\" * 60)\nprint(\"\\nThis is the REAL test: train on 9 diseases, test on 1 unseen disease\")\nprint(\"If the model learned generalizable patterns, it should still perform well.\\n\")\n\nfrom sklearn.base import clone\n\ndef disease_level_cv(model, df_dataset, df_baseline, feature_cols, baseline_cols, selected_disease_ids):\n    \"\"\"\n    Leave-One-Disease-Out cross-validation.\n    Train on all diseases except one, test on the held-out disease.\n    \"\"\"\n    results_per_disease = []\n    \n    for held_out_disease in selected_disease_ids:\n        # Split by disease\n        train_mask = df_dataset['disease_id'] != held_out_disease\n        test_mask = df_dataset['disease_id'] == held_out_disease\n        \n        # Skip if test set is too small\n        if test_mask.sum() < 5:\n            continue\n        \n        # Check if test set has both classes\n        y_test_check = df_dataset.loc[test_mask, 'label'].values\n        if len(np.unique(y_test_check)) < 2:\n            # Skip diseases with only one class in test\n            continue\n        \n        # Prepare features\n        X_train_interaction = df_dataset.loc[train_mask, feature_cols].values\n        X_test_interaction = df_dataset.loc[test_mask, feature_cols].values\n        \n        X_train_baseline = df_baseline.loc[train_mask].values\n        X_test_baseline = df_baseline.loc[test_mask].values\n        \n        X_train = np.hstack([X_train_interaction, X_train_baseline])\n        X_test = np.hstack([X_test_interaction, X_test_baseline])\n        \n        y_train = df_dataset.loc[train_mask, 'label'].values\n        y_test = df_dataset.loc[test_mask, 'label'].values\n        \n        # Train and evaluate\n        model_clone = clone(model)\n        model_clone.fit(X_train, y_train)\n        \n        y_pred = model_clone.predict(X_test)\n        y_proba = model_clone.predict_proba(X_test)[:, 1]\n        \n        # Get disease name\n        disease_name = df_dataset.loc[test_mask, 'disease_name'].iloc[0]\n        \n        # Compute metrics\n        acc = accuracy_score(y_test, y_pred)\n        try:\n            auc = roc_auc_score(y_test, y_proba)\n        except:\n            auc = np.nan\n        f1 = f1_score(y_test, y_pred)\n        \n        results_per_disease.append({\n            'disease_id': held_out_disease,\n            'disease_name': disease_name,\n            'n_test': len(y_test),\n            'n_positive': y_test.sum(),\n            'n_negative': len(y_test) - y_test.sum(),\n            'accuracy': acc,\n            'roc_auc': auc,\n            'f1': f1\n        })\n        \n    return pd.DataFrame(results_per_disease)\n\n# Run disease-level CV for Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\ndisease_cv_results = disease_level_cv(\n    rf_model, df_dataset, df_baseline, \n    feature_cols_safe, baseline_cols, selected_disease_ids\n)\n\nprint(\"Results per held-out disease:\")\nprint(\"-\" * 80)\nprint(f\"{'Disease':<35} {'N_test':>7} {'Pos/Neg':>10} {'Accuracy':>10} {'ROC-AUC':>10} {'F1':>10}\")\nprint(\"-\" * 80)\n\nfor _, row in disease_cv_results.iterrows():\n    print(f\"{row['disease_name'][:35]:<35} {row['n_test']:>7} {int(row['n_positive']):>4}/{int(row['n_negative']):<4} {row['accuracy']:>10.3f} {row['roc_auc']:>10.3f} {row['f1']:>10.3f}\")\n\nprint(\"-\" * 80)\nprint(f\"{'MEAN':<35} {'':<7} {'':<10} {disease_cv_results['accuracy'].mean():>10.3f} {disease_cv_results['roc_auc'].mean():>10.3f} {disease_cv_results['f1'].mean():>10.3f}\")\nprint(f\"{'STD':<35} {'':<7} {'':<10} {disease_cv_results['accuracy'].std():>10.3f} {disease_cv_results['roc_auc'].std():>10.3f} {disease_cv_results['f1'].std():>10.3f}\")\n\n# Compare with standard CV\nprint(\"\\n\" + \"=\" * 60)\nprint(\"COMPARISON: Standard CV vs Disease-Level CV\")\nprint(\"=\" * 60)\nstandard_auc = results['RF_Combined_Safe']['roc_auc_mean']\ndisease_auc = disease_cv_results['roc_auc'].mean()\ndrop = standard_auc - disease_auc\n\nprint(f\"\\n  Standard 5-fold CV ROC-AUC:     {standard_auc:.3f} ± {results['RF_Combined_Safe']['roc_auc_std']:.3f}\")\nprint(f\"  Disease-level CV ROC-AUC:       {disease_auc:.3f} ± {disease_cv_results['roc_auc'].std():.3f}\")\nprint(f\"  Performance drop:               {drop:+.3f} ({100*drop/standard_auc:.1f}% relative)\")\n\nif drop > 0.1:\n    print(f\"\\n  ⚠️  SIGNIFICANT DROP ({drop:.2f})!\")\n    print(\"     The model was likely memorizing disease-specific patterns,\")\n    print(\"     not learning generalizable drug-disease interactions.\")\nelif drop > 0.05:\n    print(f\"\\n  ⚠️  MODERATE DROP ({drop:.2f})\")\n    print(\"     Some disease-specific memorization, but model has some generalization.\")\nelse:\n    print(f\"\\n  ✓  SMALL DROP ({drop:.2f})\")\n    print(\"     Model appears to learn generalizable patterns!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Feature Importance Analysis\nprint(\"Analyzing feature importance...\")\nprint(\"=\" * 60)\n\n# Train a final RF model on all data for feature importance\nrf_final = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\nrf_final.fit(X_combined_safe, y)\n\n# Get feature names\nall_feature_names = feature_cols_safe + baseline_cols\n\n# Get importance scores\nimportances = rf_final.feature_importances_\nimportance_df = pd.DataFrame({\n    'feature': all_feature_names,\n    'importance': importances\n}).sort_values('importance', ascending=False)\n\nprint(\"\\nFeature Importance (Random Forest on Combined_Safe features):\")\nprint(\"-\" * 40)\nfor _, row in importance_df.iterrows():\n    bar = \"█\" * int(row['importance'] * 50)\n    print(f\"  {row['feature']:<25} {row['importance']:.3f} {bar}\")\n\n# Categorize features\nbio_features = ['n_shared_genes', 'n_shared_pathways', 'pathway_overlap', \n                'n_disease_genes', 'n_disease_pathways', 'n_drug_genes', 'n_drug_pathways']\ngraph_features = ['drug_degree', 'disease_degree', 'drug_betweenness', 'disease_betweenness',\n                  'drug_closeness', 'disease_closeness', 'degree_sum', 'degree_diff']\n\nbio_importance = importance_df[importance_df['feature'].isin(bio_features)]['importance'].sum()\ngraph_importance = importance_df[importance_df['feature'].isin(graph_features)]['importance'].sum()\n\nprint(f\"\\nImportance by feature category:\")\nprint(f\"  Biological features: {bio_importance:.3f} ({100*bio_importance:.1f}%)\")\nprint(f\"  Graph structure features: {graph_importance:.3f} ({100*graph_importance:.1f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation & Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize cross-validation results\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Prepare data for plotting\nplot_df = results_df.copy()\nplot_df['model_type'] = plot_df.index.map(lambda x: 'Logistic Regression' if x.startswith('LR') else 'Random Forest')\nplot_df['feature_set'] = plot_df.index.map(lambda x: x.split('_', 1)[1] if '_' in x else x)\n\n# 1. ROC-AUC comparison with error bars\nax = axes[0, 0]\nx = range(len(plot_df))\ncolors = ['steelblue' if 'LR' in idx else 'coral' for idx in plot_df.index]\nbars = ax.bar(x, plot_df['roc_auc_mean'], yerr=plot_df['roc_auc_std'], \n              color=colors, capsize=3, alpha=0.8)\nax.set_ylabel('ROC-AUC')\nax.set_title('ROC-AUC Comparison (5-fold CV)', fontsize=12, fontweight='bold')\nax.set_xticks(x)\nax.set_xticklabels(plot_df.index, rotation=45, ha='right', fontsize=8)\nax.set_ylim([0, 1])\nax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random baseline')\nax.legend()\nax.grid(axis='y', alpha=0.3)\n\n# 2. Accuracy comparison\nax = axes[0, 1]\nbars = ax.bar(x, plot_df['accuracy_mean'], yerr=plot_df['accuracy_std'],\n              color=colors, capsize=3, alpha=0.8)\nax.set_ylabel('Accuracy')\nax.set_title('Accuracy Comparison (5-fold CV)', fontsize=12, fontweight='bold')\nax.set_xticks(x)\nax.set_xticklabels(plot_df.index, rotation=45, ha='right', fontsize=8)\nax.set_ylim([0, 1])\nax.grid(axis='y', alpha=0.3)\n\n# 3. F1 Score comparison\nax = axes[1, 0]\nbars = ax.bar(x, plot_df['f1_mean'], yerr=plot_df['f1_std'],\n              color=colors, capsize=3, alpha=0.8)\nax.set_ylabel('F1 Score')\nax.set_title('F1 Score Comparison (5-fold CV)', fontsize=12, fontweight='bold')\nax.set_xticks(x)\nax.set_xticklabels(plot_df.index, rotation=45, ha='right', fontsize=8)\nax.set_ylim([0, 1])\nax.grid(axis='y', alpha=0.3)\n\n# 4. Feature importance\nax = axes[1, 1]\ntop_n = 10\ntop_importance = importance_df.head(top_n)\ny_pos = range(len(top_importance))\nax.barh(y_pos, top_importance['importance'], color='gold', alpha=0.8)\nax.set_yticks(y_pos)\nax.set_yticklabels(top_importance['feature'])\nax.set_xlabel('Importance')\nax.set_title(f'Top {top_n} Features (RF Combined_Safe)', fontsize=12, fontweight='bold')\nax.invert_yaxis()\nax.grid(axis='x', alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Print best model\nbest_model = plot_df['roc_auc_mean'].idxmax()\nprint(f\"\\n{'='*60}\")\nprint(f\"BEST MODEL: {best_model}\")\nprint(f\"{'='*60}\")\nprint(f\"  ROC-AUC: {plot_df.loc[best_model, 'roc_auc_mean']:.3f} ± {plot_df.loc[best_model, 'roc_auc_std']:.3f}\")\nprint(f\"  Accuracy: {plot_df.loc[best_model, 'accuracy_mean']:.3f} ± {plot_df.loc[best_model, 'accuracy_std']:.3f}\")\nprint(f\"  F1: {plot_df.loc[best_model, 'f1_mean']:.3f} ± {plot_df.loc[best_model, 'f1_std']:.3f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Confusion matrix for best model (using holdout set)\nfrom sklearn.model_selection import train_test_split\n\n# Create a holdout split for confusion matrix visualization\nX_train, X_test, y_train, y_test = train_test_split(\n    X_combined_safe, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Train best model on training set\nbest_model_obj = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\nbest_model_obj.fit(X_train, y_train)\ny_pred = best_model_obj.predict(X_test)\ny_proba = best_model_obj.predict_proba(X_test)[:, 1]\n\n# Plot confusion matrix\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Confusion matrix\nax = axes[0]\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n            xticklabels=['Indication\\n(Therapeutic)', 'Contraindication\\n(Adverse)'],\n            yticklabels=['Indication\\n(Therapeutic)', 'Contraindication\\n(Adverse)'])\nax.set_title('Confusion Matrix (Holdout Test Set)', fontsize=12, fontweight='bold')\nax.set_ylabel('True Label')\nax.set_xlabel('Predicted Label')\n\n# ROC Curve\nfrom sklearn.metrics import roc_curve, auc\nax = axes[1]\nfpr, tpr, _ = roc_curve(y_test, y_proba)\nroc_auc = auc(fpr, tpr)\nax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\nax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.05])\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.set_title('ROC Curve (RF Combined_Safe)', fontsize=12, fontweight='bold')\nax.legend(loc='lower right')\nax.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Classification report\nprint(\"\\nClassification Report (Holdout Test Set):\")\nprint(\"-\" * 50)\nprint(classification_report(y_test, y_pred, \n                           target_names=['Indication (Therapeutic)', 'Contraindication (Adverse)']))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary & Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "1. **Feature Performance**: Which feature set works best?\n",
    "2. **Model Comparison**: LR vs RF performance\n",
    "3. **Important Features**: What drives predictions?\n",
    "\n",
    "### Next Steps for Full Model:\n",
    "1. **GNN Integration**: Use graph neural networks to capture complex interactions\n",
    "2. **More Disease Areas**: Expand to additional disease areas\n",
    "3. **External Data**: Integrate DisGeNET and DrugBank for richer gene mappings\n",
    "4. **Feature Engineering**: Add temporal, dosage, and patient-specific features\n",
    "5. **Evaluation**: Cross-validation, external validation sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary & Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "1. **Feature Performance**: Which feature set works best?\n",
    "2. **Model Comparison**: LR vs RF performance\n",
    "3. **Important Features**: What drives predictions?\n",
    "\n",
    "### Next Steps for Full Model:\n",
    "1. **GNN Integration**: Use graph neural networks to capture complex interactions\n",
    "2. **More Disease Areas**: Expand to additional disease areas\n",
    "3. **External Data**: Integrate DisGeNET and DrugBank for richer gene mappings\n",
    "4. **Feature Engineering**: Add temporal, dosage, and patient-specific features\n",
    "5. **Evaluation**: Cross-validation, external validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Final summary with improved methodology\nprint(\"=\" * 60)\nprint(\"MVP SUMMARY (EXPANDED & RIGOROUS EVALUATION)\")\nprint(\"=\" * 60)\n\nprint(f\"\\n📊 DATASET:\")\nprint(f\"  Disease areas: {len(selected_disease_ids)} (expanded from 2)\")\nprint(f\"  Drugs: {len(selected_drug_ids)} (expanded from 20)\")\nprint(f\"  Total examples: {len(df_dataset)}\")\nprint(f\"    Positive (contraindication): {int(df_dataset['label'].sum())}\")\nprint(f\"    Negative (indication): {len(df_dataset) - int(df_dataset['label'].sum())}\")\nprint(f\"    Class balance: {min(df_dataset['label'].mean(), 1-df_dataset['label'].mean()):.1%} minority\")\n\nprint(f\"\\n🔬 FEATURES:\")\nprint(f\"  Biological features (safe): {len(feature_cols_safe)}\")\nprint(f\"  Graph structure features: {len(baseline_cols)}\")\nprint(f\"  Total (combined safe): {len(feature_cols_safe) + len(baseline_cols)}\")\n\nprint(f\"\\n📈 EVALUATION METHOD:\")\nprint(f\"  5-fold stratified cross-validation\")\nprint(f\"  ~{len(y)//5} test samples per fold (vs 8 before!)\")\n\nbest_model_name = results_df['roc_auc_mean'].idxmax()\nbest_results = results_df.loc[best_model_name]\n\nprint(f\"\\n🏆 BEST MODEL: {best_model_name}\")\nprint(f\"  ROC-AUC: {best_results['roc_auc_mean']:.3f} ± {best_results['roc_auc_std']:.3f}\")\nprint(f\"  Accuracy: {best_results['accuracy_mean']:.3f} ± {best_results['accuracy_std']:.3f}\")\nprint(f\"  F1 Score: {best_results['f1_mean']:.3f} ± {best_results['f1_std']:.3f}\")\n\n# Interpret results\nprint(f\"\\n💡 INTERPRETATION:\")\nif best_results['roc_auc_mean'] > 0.7:\n    print(\"  ✓ Model shows meaningful predictive power (ROC-AUC > 0.7)\")\nelse:\n    print(\"  ⚠ Model shows limited predictive power (ROC-AUC ≤ 0.7)\")\n\nif best_results['roc_auc_std'] < 0.05:\n    print(\"  ✓ Results are stable across folds (std < 0.05)\")\nelse:\n    print(\"  ⚠ High variance across folds - results may be unreliable\")\n\n# Compare feature sets\nbaseline_auc = results_df.loc['RF_Baseline', 'roc_auc_mean'] if 'RF_Baseline' in results_df.index else 0\ncombined_auc = results_df.loc['RF_Combined_Safe', 'roc_auc_mean'] if 'RF_Combined_Safe' in results_df.index else 0\nif combined_auc > baseline_auc + 0.02:\n    print(\"  ✓ Biological features add value beyond graph structure\")\nelse:\n    print(\"  ⚠ Biological features don't significantly improve over baseline\")\n\nprint(f\"\\n🔮 NEXT STEPS:\")\nprint(\"  1. Add more diverse diseases (different therapeutic areas)\")\nprint(\"  2. Implement disease-level cross-validation (train/test on different diseases)\")\nprint(\"  3. Try GNN models to capture deeper graph patterns\")\nprint(\"  4. Add drug chemical structure features (fingerprints)\")\nprint(\"  5. External validation on newly approved drugs\")\n\nprint(\"\\n\" + \"=\" * 60)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "cs224n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}